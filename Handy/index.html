<!DOCTYPE html>
<html>
<head>
  <link rel="icon" href="./static/images/icon.png">
  <meta charset="utf-8">
  <meta name="description"
        content="Handy: Towards a high fidelity 3D hand shape and appearance model">
  <meta name="keywords" content="Hand, 3D, Texture, Modeling">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Handy: Towards a high fidelity 3D hand shape and appearance model</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Handy: Towards a high fidelity 3D hand shape and appearance model</h1>          
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="">Rolandos Alexandros Potamias</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.ploumpis.com/">Stylianos Ploumpis</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.doc.ic.ac.uk/~sm3515/">Stylianos Moschoglou</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Vasilios Triantafyllou</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://www.imperial.ac.uk/people/s.zafeiriou">Stefanos Zafeiriou</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Imperial College London, United Kingdom</span>
            <span class="author-block"><sup>2</sup>Cosmos Designs Ltd, Greece</span>
          </div>
          <br>
          <span class="author-block">
            <h1 class="title is-size-4  publication-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</h1>
          </span>
          <br>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Potamias_Handy_Towards_a_High_Fidelity_3D_Hand_Shape_and_Appearance_CVPR_2023_paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2112.00585"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/F4hTHKZ8JNM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
               </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/rolpotamias/handy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Models</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_fig.jpg" alt="method" class="center">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Over the last few years, with the advent of virtual and augmented reality, an enormous amount of research has been focused on modelling, tracking and reconstructing human hands. Given their power to express human behaviour, hands have been a very important, but challenging component of the human body. Currently, most of the state-of-the-art reconstruction and pose estimation methods rely on the low polygon MANO model. Apart from its low polygon count, MANO model was trained with only 31 adult subjects, which not only limits its expressive power but also imposes unnecessary shape reconstruction constraints on pose estimation methods. Moreover, hand appearance remains almost unexplored and neglected from the majority of hand reconstruction methods. In this work, we propose "Handy", a large-scale model of the human hand, modelling both shape and appearance composed of over 1200 subjects which we make publicly available for the benefit of the research community. In contrast to current models, our proposed hand model was trained on a dataset with large diversity in age, gender, and ethnicity, which tackles the limitations of MANO and accurately reconstructs out-of-distribution samples. In order to create a high quality texture model, we trained a powerful GAN, which preserves high frequency details and is able to generate high resolution hand textures. To showcase the capabilities of the proposed model, we built a synthetic dataset of textured hands and trained a hand pose estimation network to reconstruct both the shape and appearance from single images. As it is demonstrated in an extensive series of quantitative as well as qualitative experiments, our model proves to be robust against the state-of-the-art and realistically captures the 3D hand shape and pose along with a high frequency detailed texture even in adverse "in-the-wild" conditions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">CVPR 2023 Presentation</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/F4hTHKZ8JNM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>

          </iframe>

        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
    <!-- Method overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
        <p>
            Handy is a large-scale shape and appearance model of the human hand. Handy is composed by 1208 subjects with various ages and ethnicities, tackling the limitation of previous models to accurately model diverse hands. 
        </p>
        <div>
            <img src="./static/images/handy.png" alt="method" class="center">
          </div>
        <p>
           To create Handy, we initially register the raw scans to a common template and then we apply Principal Component Analysis to model hand shape variations. In order to model the hand appearance we utilize a style-based GAN trained on the UV textures of hands. The proposed model manages to achieve photorealistic reconstructions. 
        </p>
          </div>
          <div>
            <img src="./static/images/ITW_hands-compressed.jpg" alt="method" class="center">
          </div>
      </div>
    </div>
  </div>
</section>
  
  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Potamias_2023_CVPR,
      author    = {Potamias, Rolandos Alexandros and Ploumpis, Stylianos and Moschoglou, Stylianos and Triantafyllou, Vasileios and Zafeiriou, Stefanos},
      title     = {Handy: Towards a High Fidelity 3D Hand Shape and Appearance Model},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2023},
      pages     = {4670-4680}
  }
</code></pre>
  </div>
</section>


<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The source code of this website is borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
