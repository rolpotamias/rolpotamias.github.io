
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SAGS: Structure-Aware 3D Gaussian Splatting</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jonbarron.info/zipnerf/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://rolpotamias.github.io/sags/"/>
    <meta property="og:title" content="SAGS: Structure-Aware 3D Gaussian Splatting" />
    <meta property="og:description" content="Following the advent of NeRFs, 3D Gaussian Splatting (3D-GS) has paved the way to real-time neural rendering overcoming the computational burden of volumetric methods. Following the pioneering work of 3D-GS, several methods have attempted to achieve compressible and high-fidelity performance. However, by employing a geometry-agnostic optimization scheme, these methods neglect the inherent 3D structure of the scene, thereby restricting the expressivity and the quality of the representation, resulting in various floating points and artifacts. In this work, we propose a structure-aware Gaussian Splatting method (SAGS) that implicitly encodes the geometry of the scene, which reflects to state-of-the-art rendering performance and reduced storage requirements on benchmark novel-view synthesis datasets. SAGS is founded on a local-global graph representation that facilitates the learning of complex scenes and enforces meaningful point displacements that preserve the scene's geometry. Additionally, we introduce a lightweight version of SAGS, using a simple yet effective mid-point interpolation scheme, which showcases a compact representation of the scene with up to 20-times size reduction without the reliance on any compression strategies. Extensive experiments across multiple benchmark datasets demonstrate the superiority of SAGS compared to state-of-the-art 3D-GS methods under both rendering quality and model size. Besides, we demonstrate that our structure-aware method can effectively mitigate floating artifacts and irregular distortions of previous methods while obtaining precise depth maps. Code and models will be publicly available." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SAGS: Structure-Aware 3D Gaussian Splatting" />
    <meta name="twitter:description" content="Following the advent of NeRFs, 3D Gaussian Splatting (3D-GS) has paved the way to real-time neural rendering overcoming the computational burden of volumetric methods. Following the pioneering work of 3D-GS, several methods have attempted to achieve compressible and high-fidelity performance. However, by employing a geometry-agnostic optimization scheme, these methods neglect the inherent 3D structure of the scene, thereby restricting the expressivity and the quality of the representation, resulting in various floating points and artifacts. In this work, we propose a structure-aware Gaussian Splatting method (SAGS) that implicitly encodes the geometry of the scene, which reflects to state-of-the-art rendering performance and reduced storage requirements on benchmark novel-view synthesis datasets. SAGS is founded on a local-global graph representation that facilitates the learning of complex scenes and enforces meaningful point displacements that preserve the scene's geometry. Additionally, we introduce a lightweight version of SAGS, using a simple yet effective mid-point interpolation scheme, which showcases a compact representation of the scene with up to 20-times size reduction without the reliance on any compression strategies. Extensive experiments across multiple benchmark datasets demonstrate the superiority of SAGS compared to state-of-the-art 3D-GS methods under both rendering quality and model size. Besides, we demonstrate that our structure-aware method can effectively mitigate floating artifacts and irregular distortions of previous methods while obtaining precise depth maps. Code and models will be publicly available." />
    <meta name="twitter:image" content="https://rolpotamias.github.io/sags/img/Teaser.png" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>SAGS</b>: Structure-Aware 3D Gaussian Splatting</br> 
                <small>
                arXiv 2024
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://github.com/Vagver">
                          Evangelos Ververas<sup>1,2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://rolpotamias.github.io/">
                            Rolandos Alexandros Potamias<sup>1,2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=9a1PjCIAAAAJ">
                          Jifei Song<sup>2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://jiankangdeng.github.io/">
                          Jiankang Deng<sup>1,2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.imperial.ac.uk/people/s.zafeiriou">
                          Stefanos Zafeiriou<sup>1</sup>
                        </a>
                    </li>
                    </br>
                    <ul class="list-inline">
                        <li>
                            Imperial College London<sup>1</sup>
                        </li>
                        <li>
                            Huawei Noahâ€™s Ark Lab UKr<sup>2</sup>
                        </li>
                    </ul>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/">
                            <image src="img/arxiv-logomark-small.svg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code (Coming Soon) </strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/Teaser_SAGS.mp4" type="video/mp4" />
                </video>
						</div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
            <image src="img/Teaser.png" height="225px">
			</div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Following the advent of NeRFs, 3D Gaussian Splatting (3D-GS) has paved the way to real-time neural rendering overcoming the computational burden of volumetric methods. Following the pioneering work of 3D-GS, several methods have attempted to achieve compressible and high-fidelity performance. However, by employing a geometry-agnostic optimization scheme, these methods neglect the inherent 3D structure of the scene, thereby restricting the expressivity and the quality of the representation, resulting in various floating points and artifacts. In this work, we propose a structure-aware Gaussian Splatting method (SAGS) that implicitly encodes the geometry of the scene, which reflects to state-of-the-art rendering performance and reduced storage requirements on benchmark novel-view synthesis datasets. SAGS is founded on a local-global graph representation that facilitates the learning of complex scenes and enforces meaningful point displacements that preserve the scene's geometry. Additionally, we introduce a lightweight version of SAGS, using a simple yet effective mid-point interpolation scheme, which showcases a compact representation of the scene with up to 20 times size reduction without the reliance on any compression strategies. Extensive experiments across multiple benchmark datasets demonstrate the superiority of SAGS compared to state-of-the-art 3D-GS methods under both rendering quality and model size. Besides, we demonstrate that our structure-aware method can effectively mitigate floating artifacts and irregular distortions of previous methods while obtaining precise depth maps. Code and models will be publicly available.                </p>
            </div>
        </div>

<br>

<br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>
				<table style="width: 100%; border-collapse: collapse;">
				  <tr>
				    <td style="text-align: center;">
                        <image src="img/Method.png" height="170px"></image>
					</td>
				    <td style="text-align: center;">
		                <video id="v0" width="100%" autoplay loop muted>
		                  <source src="img/hexify_test.mp4" type="video/mp4" />
		                </video>
					</td>
				  </tr>
				</table>
                <p class="text-justify">
                    Given a point cloud obtained from COLMAP \cite{sfm}, we initially apply a curvature-based densification step to populate under-represented areas. We then apply k-NN search to link points within local regions and create a point set graph. Leveraging the inductive biases of graph neural networks, we learn a local-global structural feature for each point. Using a set of small MLPs we decode the structural features to 3D Gaussian attributes, i.e., color, opacity, covariance and point displacements for the initial point position. Finally, we render the 3D Gaussians following the 3D-GS Gaussian rasterizer
                </p>
            </div>
        </div>
<br>
        <!--  VIDEO 1  --> 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <p class="text-justify">
                    Comparison between the proposed and the Scaffold-GS method on the scene's structure preservation. The proposed method can accurately capture sharp edges and suppress 'floater' artifacts that are visible on the Scaffold-GS depth maps.
            
                <video class="video" width=100% id="garden" loop playsinline autoplay muted src="img/garden_comparison.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="gardenMerge"></canvas>
                <video class="video" width=100% id="amsterdam" loop playsinline autoplay muted src="img/amsterdam_comparison.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="amsterdamMerge"></canvas>
                </div>
        </div>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{ververas2024sags,
    title={SAGS: Structure-Aware 3D Gaussian Splatting},
    author={Evangelos Ververal and Rolandos Alexandros Potamias and 
            Jifei Song and Jiankang Deng and Stefanos Zafeiriou},
    journal={arxiv},
    year={2024}
}</textarea>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
